{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adichat08/CNN-for-Bird-s-Eye-Human-Detection/blob/main/Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gJEgAiiF4_Q"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports specific to the model construction\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform"
      ],
      "metadata": {
        "id": "UTb9qR9_NZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLQvZEcpVHD5"
      },
      "outputs": [],
      "source": [
        "# This is code to check GPU usage\n",
        "\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#     process = psutil.Process(os.getpid())\n",
        "#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of basic VGG 16 architecture"
      ],
      "metadata": {
        "id": "uGqU88OXEdsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Defining the VGG-16 model architecture\n",
        "vgg_16 = keras.Sequential([\n",
        "    # Convolutional Block 1\n",
        "    # The first convolutional layer is the input layer and expects images of size 150x150 pixels with 3 color channels (RGB).\n",
        "    # 64 filters are chosen to capture a variety of low-level features in the input images.\n",
        "    # A 3x3 kernel size is commonly used in CNNs to capture spatial information.\n",
        "    # 'Same' padding is chosen so that the spatial dimensions of the output feature maps match the dimensions of the input images.\n",
        "    # ReLU activation is used as non-linearity, as opposed to other activation functions such as sigmoid. ReLU is used more commonly as it better addresses the vanising gradient problem and results in more sparse activation.\n",
        "    layers.Conv2D(input_shape=(150, 150, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    # Max pooling is used to downsample the feature maps, reducing spatial dimensions and as a result, computational complexity.\n",
        "    # A pool size of 2x2 and a stride of 2x2 are chosen to halve the spatial dimensions after each max-pooling layer.\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    # The number of filters is increased so that the model can now capture higher-level features (it can learn more complex patterns)\n",
        "    # The same padding and ReLU activation function are used for consistency.\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    # Max pooling is still downsampling feature maps, while also preserving important features that the model identified.\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    # Increasing the number of filters to capture even more abstract features.\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "\n",
        "    # Convolutional Block 4\n",
        "    # Continuing the trend of increasing filters for deeper representation.\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "    # Convolutional Block 5\n",
        "    # Keeping the number of filters consistent for the final convolutional layers.\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    # Flattening the 3D convolutional outputs into a 1D vector for input to the fully connected layers.\n",
        "    # Dense layers with 4096 units are chosen to preserve the high-level feature representations acquired in the deeper layers.\n",
        "    # ReLU activation used for the aformentioned reasons.\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=4096, activation=\"relu\"),\n",
        "    layers.Dense(units=4096, activation=\"relu\"),\n",
        "\n",
        "    # Output Layer\n",
        "    # The output layer consists of 2 units, representing the two classes (human target identified or not).\n",
        "    # Softmax activation is chosen for the output layer to produce class probabilities.\n",
        "    layers.Dense(units=2, activation=\"softmax\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "BoZgH5yk-52X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "# Adam is a common optimizer and a learning rate of 0.001 is generally shown to be stable and work well for a variety of tasks. This is an intial hyperparameter choice.\n",
        "opt = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "-pnuWA6tibIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OjwfBE4cidSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16.summary()"
      ],
      "metadata": {
        "id": "R8SL4ke0i1g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of modified ResNet50 architecture"
      ],
      "metadata": {
        "id": "CIi19DqaEjyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is an explanation for the general structure of the model:\n",
        "\n",
        "# Convolutional Block and Identity Block Structure:\n",
        "# The ResNet architecture is based on the concept of residual learning, where the main path (through convolutional layers) is augmented with a shortcut connection (skipping layers).\n",
        "# Both convolutional_block and identity_block functions are fundamental building blocks of ResNet, each consisting of multiple convolutional layers, followed by batch normalization and ReLU activation.\n",
        "\n",
        "# Number of Filters:\n",
        "# The number of filters in each convolutional layer is carefully chosen to balance model complexity and representational capacity.\n",
        "# For example, in the convolutional_block, the number of filters gradually increases from F1 to F3, capturing more abstract features as the network progresses.\n",
        "\n",
        "# Kernel Size and Padding:\n",
        "# Kernel size of 1x1, 3x3, and occasionally 7x7 is used in different layers to capture different levels of spatial information.\n",
        "# Same padding is used in most convolutional layers to preserve spatial dimensions.\n",
        "\n",
        "# Striding:\n",
        "# Striding is employed in the convolutional_block to reduce spatial dimensions (e.g., from 56x56 to 28x28) when transitioning between different stages of the network.\n",
        "\n",
        "# Pooling:\n",
        "# Average pooling is applied at the end of the network to aggregate spatial information and reduce spatial dimensions before the final output layer.\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block in ResNet50.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- list of integers, defining the number of filters in the CONV layers\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    # Define name basis for the layers\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Add shortcut value to main path and pass it through a ReLU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block in ResNet50.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    # Define name basis for the layers\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Add shortcut value to main path and pass it through a ReLU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "    \"\"\"\n",
        "    Implementation of the ResNet50 architecture.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    # Define input with zero padding\n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # Average pooling layer\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "sygLJXDVGHna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(input_shape=(150, 150, 3))"
      ],
      "metadata": {
        "id": "De-9Tyx0Nu-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning implementation attempt"
      ],
      "metadata": {
        "id": "O1TLKWwYEx1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headModel = base_model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)"
      ],
      "metadata": {
        "id": "95VwKcHvObTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=headModel)"
      ],
      "metadata": {
        "id": "8jX1sPkjOcUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nAQKqF8eOghD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.load_weights('/content/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')"
      ],
      "metadata": {
        "id": "iCrMWgOLRAC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "7uCLZjJpRHch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "gk4x8pDCRKtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)"
      ],
      "metadata": {
        "id": "gvaAgkp9RRGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hNwRKgAAPG8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 8, validation_split = 0.2, verbose = 1, callbacks = [es])"
      ],
      "metadata": {
        "id": "lYo4Y9kJO8kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are tests for basic CNNs"
      ],
      "metadata": {
        "id": "_Lg0X8NFE2sQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlrkWVT4F4_R"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn = keras.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRTgQ5trMapk"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_2 = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtWkv57qPTh9"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_3 = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(125, 125, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVv-Mqci5NdR"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_3_1 = models.Sequential([\n",
        "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(125, 125, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_3_2 = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(125, 125, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "TzvtT9w6Ytx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA_vQ9PAXTgF"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_4 = models.Sequential([\n",
        "    layers.Conv2D(filters=128, kernel_size=(7, 7), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(5, 5), activation='relu'),\n",
        "    #layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixu6M1Lt0IW6"
      },
      "outputs": [],
      "source": [
        "# Testing a CNN\n",
        "\n",
        "cnn_5 = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEI333jZ6ChQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn_4 = models.Sequential([\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    #layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "    #layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkRmEzfvF4_R"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h2GBjyR3u5g"
      },
      "outputs": [],
      "source": [
        "cnn_2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEvwnZinPfYL"
      },
      "outputs": [],
      "source": [
        "cnn_3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAsX4nJ45nFt"
      },
      "outputs": [],
      "source": [
        "cnn_3_1.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3_2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hpp_5KdpY302"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L4nb-SgYEUF"
      },
      "outputs": [],
      "source": [
        "cnn_4.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA3upvO20NbX"
      },
      "outputs": [],
      "source": [
        "cnn_5.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zTae4HdUjXXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting models"
      ],
      "metadata": {
        "id": "-O25QOQUFPxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_4 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=200, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "2s_uHzwNEgDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_3 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=500, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "DY7WSEK8xbGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_3 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=15, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "HQXaYGnEvgz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_4 = cnn_3.fit(FIRE_X_train, FIRE_y_train, epochs=15, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "NHot3N8bTO5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_2 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 4, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "o0JtXiU5tFzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_1 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 16, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "kway7uuKsbMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1_1 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 1, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "uMyFpJ4ZaqCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_2 = cnn_3_2.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "ggBI_LdgY7Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1 = cnn_3_1.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "-AQj2tteXMkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "jMCLoVkj06Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_c3_1 = cnn_3.fit(expanded_X_train, expanded_y_train, epochs=50, batch_size = 4, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "XPwDrG4G-wcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_2.fit(X_train_full, y_train_full, epochs=500, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "MyaPuqv_-SVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_2.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 4, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "MS02hKQRsge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_2.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 8, validation_split = 0.3)"
      ],
      "metadata": {
        "id": "4cV2l3CT3e_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_2.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "n7w8b66EgVla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdG_pE3rGPXh"
      },
      "outputs": [],
      "source": [
        "history_104 = cnn_3.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 8, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_4.fit(expanded_dataset, expanded_y, epochs=20, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "QS4YApqRCMDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_4.fit(expanded_dataset, expanded_y, epochs=100, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "Lyhk9Z1UEyqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_104 = cnn_4.fit(expanded_dataset, expanded_y, epochs=50, batch_size = 8, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "HGroTE40KKxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying graphs"
      ],
      "metadata": {
        "id": "SflcHSsSFSB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_104.history['accuracy'])\n",
        "plt.plot(history_104.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_104.history['loss'])\n",
        "plt.plot(history_104.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mr508xqSBZG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh66A18E2rg4"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgdhxpqz8ONG"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-LTmCLKS1ju"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_3.history['accuracy'])\n",
        "plt.plot(history_3.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_3.history['loss'])\n",
        "plt.plot(history_3.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq-PRnlGZ0ib"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_4.history['accuracy'])\n",
        "plt.plot(history_4.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_4.history['loss'])\n",
        "plt.plot(history_4.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbKpzno0mIKt"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_5.history['accuracy'])\n",
        "plt.plot(history_5.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_5.history['loss'])\n",
        "plt.plot(history_5.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlPs0q3MrGIp"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_11.history['accuracy'])\n",
        "plt.plot(history_11.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(history_11.history['loss'])\n",
        "plt.plot(history_11.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking results"
      ],
      "metadata": {
        "id": "GtylK3qJFZl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFaYeYPnB3VH"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vIQMnMW_l5Y"
      },
      "outputs": [],
      "source": [
        "cnn_3_1.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npEvl1MGBq3E"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG190ULt7R9R"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDgzaV_w9C-E"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThUL_NmIAlaZ"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBZYtwXRC1Rr"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5WnrzacFCoy"
      },
      "outputs": [],
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "wYo_qnW7syfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXbU1A_wm-3C"
      },
      "outputs": [],
      "source": [
        "cnn_4.evaluate(X_test ,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_4.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "mYJeUzfdJ3Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_4.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "nN9t6CjqPmQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_2.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "jYLkOMU9nF_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "U-cv2Zw5PtMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16.evaluate(X_test ,y_test)"
      ],
      "metadata": {
        "id": "qjF1PpnRqJPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "CZpFv1jt15oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "VAytxldRAa9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3_1.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "_eAx-lCiYeON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3_2.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "7EgjE21jaVoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "4w2a6_6Pf8GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "Kz_7l8AJvI7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "Ezi9dhiBxPyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "aNrRumPsETLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(expanded_X_test ,expanded_y_test)"
      ],
      "metadata": {
        "id": "5ZmZh8plJG5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(FIRE_dataset, humans_in_fire_y)"
      ],
      "metadata": {
        "id": "JqYP1h_QPkXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_3.evaluate(FIRE_X_test, FIRE_y_test)"
      ],
      "metadata": {
        "id": "iBbr6ouXTY6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raU5JGDCF4_S"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = cnn_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_1 = cnn_3.predict(FIRE_X_test)"
      ],
      "metadata": {
        "id": "ZhJNdzqGQlMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mml02zd6F4_S"
      },
      "outputs": [],
      "source": [
        "y_classes_cnn = [np.argmax(element) for element in y_pred_cnn_1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlR9bNmMF4_S"
      },
      "outputs": [],
      "source": [
        "print(list(y_test[:10]))\n",
        "print(y_classes_cnn[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report: \\n\", classification_report(FIRE_y_test, y_classes_cnn))"
      ],
      "metadata": {
        "id": "BCYXYrWLQ73p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUP3iWGHF4_S"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report: \\n\", classification_report(y_test, y_classes_cnn))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report: \\n\", classification_report(y_test, y_classes_cnn))"
      ],
      "metadata": {
        "id": "l9Y0DidYYmvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report: \\n\", classification_report(y_test, y_classes_cnn))"
      ],
      "metadata": {
        "id": "frj4t-eQadWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report: \\n\", classification_report(y_test, y_classes_cnn))"
      ],
      "metadata": {
        "id": "L6fKcjVvvNi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2gJEgAiiF4_Q"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}